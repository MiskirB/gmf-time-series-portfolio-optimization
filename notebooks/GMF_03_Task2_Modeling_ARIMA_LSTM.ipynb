{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b39e0f",
   "metadata": {},
   "source": [
    "# 03 — Task 2: Modeling (ARIMA vs LSTM) for TSLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Colab Setup ===\n",
    "!pip install -U pip --quiet\n",
    "!pip install \"numpy<2.0\" \"scipy<1.11\" --quiet\n",
    "!pip install \"pmdarima==2.0.3\" --quiet\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn statsmodels yfinance PyPortfolioOpt arch tensorflow --quiet\n",
    "import sys, os, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b49793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "START_DATE = \"2015-07-01\"\n",
    "END_DATE   = \"2025-07-31\"\n",
    "TICKERS    = [\"TSLA\", \"BND\", \"SPY\"]\n",
    "BT_START   = \"2024-08-01\"\n",
    "BT_END     = \"2025-07-31\"\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_DAILY = 0.0\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "OUT_PLOTS = \"outputs/plots\"\n",
    "OUT_MODELS = \"outputs/models\"\n",
    "OUT_METRICS = \"outputs/metrics\"\n",
    "\n",
    "for d in [DATA_DIR, OUT_PLOTS, OUT_MODELS, OUT_METRICS]:\n",
    "    os.makedirs(d, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a175da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load data ===\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "prices = pd.read_csv(f\"{DATA_DIR}/prices_adj_close.csv\", index_col=0, parse_dates=True)\n",
    "tsla = prices['TSLA'].dropna()\n",
    "train = tsla.loc[:'2023-12-31']\n",
    "test  = tsla.loc['2024-01-01':'2025-07-31']\n",
    "print(train.index.min(), \"→\", train.index.max(), \"| test:\", test.index.min(), \"→\", test.index.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ARIMA (pmdarima.auto_arima) ===\n",
    "import pmdarima as pm\n",
    "arima_model = pm.auto_arima(train, seasonal=False, stepwise=True, error_action=\"ignore\", suppress_warnings=True,\n",
    "                            max_p=5, max_q=5, max_d=2, trace=False)\n",
    "print(arima_model.summary())\n",
    "\n",
    "n_test = len(test)\n",
    "arima_fc, arima_conf = arima_model.predict(n_periods=n_test, return_conf_int=True)\n",
    "arima_fc = pd.Series(arima_fc, index=test.index, name=\"ARIMA_FC\")\n",
    "\n",
    "mae = mean_absolute_error(test, arima_fc)\n",
    "rmse = mean_squared_error(test, arima_fc, squared=False)\n",
    "mape = (np.abs((test - arima_fc)/test)).mean()*100\n",
    "print(f\"ARIMA → MAE: {mae:.2f} | RMSE: {rmse:.2f} | MAPE: {mape:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(train.index, train, label=\"Train\")\n",
    "plt.plot(test.index, test, label=\"Test\", alpha=0.8)\n",
    "plt.plot(arima_fc.index, arima_fc, label=\"ARIMA Forecast\")\n",
    "plt.fill_between(test.index, arima_conf[:,0], arima_conf[:,1], alpha=0.15, label=\"95% CI\")\n",
    "plt.title(\"TSLA — ARIMA forecast vs actual (Test)\"); plt.legend(); plt.savefig(f\"{OUT_PLOTS}/arima_test.png\"); plt.show()\n",
    "\n",
    "# Save ARIMA model\n",
    "from joblib import dump\n",
    "dump(arima_model, f\"{OUT_MODELS}/tsla_arima.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a252ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LSTM baseline ===\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ts_scaled = scaler.fit_transform(tsla.values.reshape(-1,1))\n",
    "\n",
    "split_idx = len(train)\n",
    "lookback = 60\n",
    "\n",
    "def make_seq(arr, lookback=60):\n",
    "    X,y=[],[]\n",
    "    for i in range(lookback, len(arr)):\n",
    "        X.append(arr[i-lookback:i, 0])\n",
    "        y.append(arr[i,0])\n",
    "    X = np.array(X); y = np.array(y)\n",
    "    return X[...,None], y\n",
    "\n",
    "X_train, y_train = make_seq(ts_scaled[:split_idx], lookback)\n",
    "X_test, y_test   = make_seq(ts_scaled[split_idx-lookback:], lookback)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(lookback,1)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "hist = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "yhat_scaled = model.predict(X_test).ravel()\n",
    "yhat = scaler.inverse_transform(yhat_scaled.reshape(-1,1)).ravel()\n",
    "\n",
    "# Align prediction index with test (offset due to lookback)\n",
    "pred_index = tsla.index[split_idx:][lookback:]\n",
    "lstm_fc = pd.Series(yhat, index=pred_index, name=\"LSTM_FC\")\n",
    "test_aligned = tsla[pred_index.min():pred_index.max()]\n",
    "\n",
    "mae = mean_absolute_error(test_aligned, lstm_fc)\n",
    "rmse = mean_squared_error(test_aligned, lstm_fc, squared=False)\n",
    "mape = (np.abs((test_aligned - lstm_fc)/test_aligned)).mean()*100\n",
    "print(f\"LSTM → MAE: {mae:.2f} | RMSE: {rmse:.2f} | MAPE: {mape:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(train.index, train, label=\"Train\")\n",
    "plt.plot(test.index, test, label=\"Test\", alpha=0.8)\n",
    "plt.plot(lstm_fc.index, lstm_fc, label=\"LSTM Forecast\")\n",
    "plt.title(\"TSLA — LSTM forecast vs actual (Test)\"); plt.legend(); plt.savefig(f\"{OUT_PLOTS}/lstm_test.png\"); plt.show()\n",
    "\n",
    "# Save LSTM model (optional)\n",
    "model.save(f\"{OUT_MODELS}/tsla_lstm.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8b8f4",
   "metadata": {},
   "source": [
    "> Both models evaluated on 2024–2025 test set. Proceed to Notebook 04 to generate a 12-month forecast using ARIMA (or load LSTM if you prefer)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
